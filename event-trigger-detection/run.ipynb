{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj8zUfshzS8Z",
        "outputId": "22780420-c1be-487d-95c1-e8fed7ad3281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2YZBiL8zd-n",
        "outputId": "34a0afbb-f184-4fba-bd0b-4ad7e072a66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/event_detection\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/event_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFSVSOmoQClm",
        "outputId": "94556cf9-a93c-4684-a974-f1f0c8140308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from pyvi) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.10)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyvi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF8FN0eT4Bho"
      },
      "outputs": [],
      "source": [
        "! python bert_event_detection.py --model 'vinai/phobert-base-v2' --level 'word'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sL763gagWYe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(no_train=True, train_batch_size=8, eval_batch_size=8, lr=0.0001, num_epochs=30, log_step=100, no_cuda=False, word_embedding_dim=300, use_pretrained=True, use_postag=True, postag_embedding_dim=25, hidden_size=512, dropout_rate=0.5)\n",
            "Restore best model !\n",
            "Test: f1 55.90 precision 60.39 recall 52.03\n"
          ]
        }
      ],
      "source": [
        "! python bilstm_event_sentence.py --no_train --use_pretrained --use_postag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwwQPa0mdmvi",
        "outputId": "26a4f179-5888-4503-e5ec-8acb4d80e8ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(no_train=False, train_batch_size=8, eval_batch_size=8, lr=0.0001, num_epochs=30, log_step=100, no_cuda=False, word_embedding_dim=300, use_pretrained=True, use_postag=False, postag_embedding_dim=25, hidden_size=512, dropout_rate=0.5)\n",
            "Epoch 1|30:\n",
            "Batch 1|1608: loss 3.5167 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 101|1608: loss 0.1681 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 201|1608: loss 0.1938 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.1620 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.2967 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.1033 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.1065 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0132 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0562 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0813 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0576 f1 40.00 precision 100.00 recall 25.00\n",
            "Batch 1101|1608: loss 0.1319 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 1201|1608: loss 0.0814 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.1085 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.1221 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0612 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.0775 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0064 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.1607 f1 14.60 precision 22.90 recall 11.92\n",
            "Time: 35.06\n",
            "Dev: loss 0.0756 f1 29.51 precision 68.08 recall 18.84\n",
            "Save model weight!\n",
            "\n",
            "Epoch 2|30:\n",
            "Batch 1|1608: loss 0.0336 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 101|1608: loss 0.0559 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 201|1608: loss 0.0770 f1 28.57 precision 33.33 recall 25.00\n",
            "Batch 301|1608: loss 0.1606 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.0165 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0725 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0393 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 701|1608: loss 0.0919 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0892 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0666 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1001|1608: loss 0.0253 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0579 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 1201|1608: loss 0.0708 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 1301|1608: loss 0.1007 f1 33.33 precision 50.00 recall 25.00\n",
            "Batch 1401|1608: loss 0.0375 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1501|1608: loss 0.0231 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0578 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1608|1608: loss 0.0854 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0736 f1 36.80 precision 48.44 recall 33.22\n",
            "Time: 35.25\n",
            "Dev: loss 0.0615 f1 48.29 precision 58.78 recall 40.97\n",
            "Save model weight!\n",
            "\n",
            "Epoch 3|30:\n",
            "Batch 1|1608: loss 0.0461 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 101|1608: loss 0.1946 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 201|1608: loss 0.0330 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.0277 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 401|1608: loss 0.0204 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0720 f1 44.44 precision 50.00 recall 40.00\n",
            "Batch 601|1608: loss 0.1037 f1 22.22 precision 50.00 recall 14.29\n",
            "Batch 701|1608: loss 0.0156 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0234 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0717 f1 33.33 precision 33.33 recall 33.33\n",
            "Batch 1001|1608: loss 0.0453 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1101|1608: loss 0.0527 f1 28.57 precision 100.00 recall 16.67\n",
            "Batch 1201|1608: loss 0.1104 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0431 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.1096 f1 40.00 precision 100.00 recall 25.00\n",
            "Batch 1501|1608: loss 0.0854 f1 66.67 precision 57.14 recall 80.00\n",
            "Batch 1601|1608: loss 0.0207 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1608|1608: loss 0.0222 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0626 f1 44.01 precision 53.54 recall 41.74\n",
            "Time: 36.88\n",
            "Dev: loss 0.0591 f1 45.28 precision 68.52 recall 33.82\n",
            "\n",
            "Epoch 4|30:\n",
            "Batch 1|1608: loss 0.0120 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0319 f1 57.14 precision 100.00 recall 40.00\n",
            "Batch 201|1608: loss 0.1012 f1 33.33 precision 33.33 recall 33.33\n",
            "Batch 301|1608: loss 0.0345 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 401|1608: loss 0.0369 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 501|1608: loss 0.0350 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0359 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0405 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0397 f1 57.14 precision 50.00 recall 66.67\n",
            "Batch 901|1608: loss 0.0695 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 1001|1608: loss 0.0492 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 1101|1608: loss 0.0196 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.1036 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0133 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0443 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0791 f1 60.00 precision 50.00 recall 75.00\n",
            "Batch 1601|1608: loss 0.0280 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1608|1608: loss 0.1206 f1 33.33 precision 50.00 recall 25.00\n",
            "Train: loss 0.0549 f1 48.00 precision 56.74 recall 45.97\n",
            "Time: 36.73\n",
            "Dev: loss 0.0560 f1 49.44 precision 60.93 recall 41.59\n",
            "Save model weight!\n",
            "\n",
            "Epoch 5|30:\n",
            "Batch 1|1608: loss 0.0326 f1 33.33 precision 50.00 recall 25.00\n",
            "Batch 101|1608: loss 0.0385 f1 57.14 precision 50.00 recall 66.67\n",
            "Batch 201|1608: loss 0.0434 f1 72.73 precision 100.00 recall 57.14\n",
            "Batch 301|1608: loss 0.0216 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 401|1608: loss 0.0687 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 501|1608: loss 0.0223 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0391 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 701|1608: loss 0.1016 f1 42.86 precision 50.00 recall 37.50\n",
            "Batch 801|1608: loss 0.0610 f1 25.00 precision 50.00 recall 16.67\n",
            "Batch 901|1608: loss 0.0339 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1001|1608: loss 0.0249 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0516 f1 33.33 precision 100.00 recall 20.00\n",
            "Batch 1201|1608: loss 0.0757 f1 44.44 precision 50.00 recall 40.00\n",
            "Batch 1301|1608: loss 0.0078 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0167 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1501|1608: loss 0.0190 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0312 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1608|1608: loss 0.1580 f1 66.67 precision 100.00 recall 50.00\n",
            "Train: loss 0.0490 f1 50.38 precision 58.57 recall 48.70\n",
            "Time: 36.90\n",
            "Dev: loss 0.0551 f1 50.91 precision 60.73 recall 43.82\n",
            "Save model weight!\n",
            "\n",
            "Epoch 6|30:\n",
            "Batch 1|1608: loss 0.0901 f1 22.22 precision 25.00 recall 20.00\n",
            "Batch 101|1608: loss 0.0662 f1 38.10 precision 40.00 recall 36.36\n",
            "Batch 201|1608: loss 0.0232 f1 28.57 precision 25.00 recall 33.33\n",
            "Batch 301|1608: loss 0.0381 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.0162 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.1331 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0272 f1 33.33 precision 25.00 recall 50.00\n",
            "Batch 701|1608: loss 0.0613 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0464 f1 40.00 precision 33.33 recall 50.00\n",
            "Batch 901|1608: loss 0.0157 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1001|1608: loss 0.0435 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 1101|1608: loss 0.0177 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.0126 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.0504 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.0356 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0999 f1 53.33 precision 50.00 recall 57.14\n",
            "Batch 1601|1608: loss 0.0569 f1 80.00 precision 85.71 recall 75.00\n",
            "Batch 1608|1608: loss 0.0114 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0442 f1 53.60 precision 60.77 recall 52.49\n",
            "Time: 36.78\n",
            "Dev: loss 0.0539 f1 51.82 precision 59.69 recall 45.78\n",
            "Save model weight!\n",
            "\n",
            "Epoch 7|30:\n",
            "Batch 1|1608: loss 0.0118 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 101|1608: loss 0.0499 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 201|1608: loss 0.0705 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 301|1608: loss 0.0156 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 401|1608: loss 0.0373 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 501|1608: loss 0.0132 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0377 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0312 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 801|1608: loss 0.0128 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0023 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0533 f1 66.67 precision 75.00 recall 60.00\n",
            "Batch 1101|1608: loss 0.0254 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.0305 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.0941 f1 54.55 precision 75.00 recall 42.86\n",
            "Batch 1401|1608: loss 0.0686 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0753 f1 71.43 precision 83.33 recall 62.50\n",
            "Batch 1601|1608: loss 0.0069 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0605 f1 33.33 precision 33.33 recall 33.33\n",
            "Train: loss 0.0393 f1 56.14 precision 62.60 recall 55.09\n",
            "Time: 36.82\n",
            "Dev: loss 0.0552 f1 52.91 precision 61.74 recall 46.28\n",
            "Save model weight!\n",
            "\n",
            "Epoch 8|30:\n",
            "Batch 1|1608: loss 0.0121 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0141 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0287 f1 83.33 precision 83.33 recall 83.33\n",
            "Batch 301|1608: loss 0.0205 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 401|1608: loss 0.0133 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0163 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0192 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0533 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0172 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0616 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 1001|1608: loss 0.0566 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1101|1608: loss 0.0075 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0466 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 1301|1608: loss 0.0155 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1401|1608: loss 0.0700 f1 44.44 precision 33.33 recall 66.67\n",
            "Batch 1501|1608: loss 0.1054 f1 50.00 precision 66.67 recall 40.00\n",
            "Batch 1601|1608: loss 0.0189 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1608|1608: loss 0.1297 f1 50.00 precision 50.00 recall 50.00\n",
            "Train: loss 0.0335 f1 61.31 precision 66.99 recall 60.50\n",
            "Time: 36.95\n",
            "Dev: loss 0.0552 f1 53.29 precision 56.52 recall 50.42\n",
            "Save model weight!\n",
            "\n",
            "Epoch 9|30:\n",
            "Batch 1|1608: loss 0.0198 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 101|1608: loss 0.0368 f1 83.33 precision 83.33 recall 83.33\n",
            "Batch 201|1608: loss 0.0057 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0097 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 401|1608: loss 0.0022 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0593 f1 50.00 precision 66.67 recall 40.00\n",
            "Batch 601|1608: loss 0.0444 f1 76.92 precision 83.33 recall 71.43\n",
            "Batch 701|1608: loss 0.0328 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0369 f1 33.33 precision 25.00 recall 50.00\n",
            "Batch 901|1608: loss 0.0193 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 1001|1608: loss 0.0395 f1 72.73 precision 80.00 recall 66.67\n",
            "Batch 1101|1608: loss 0.0196 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.0164 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0221 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1401|1608: loss 0.0083 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0101 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0216 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1608|1608: loss 0.0449 f1 66.67 precision 100.00 recall 50.00\n",
            "Train: loss 0.0294 f1 64.50 precision 69.52 recall 63.81\n",
            "Time: 36.96\n",
            "Dev: loss 0.0591 f1 51.89 precision 58.15 recall 46.84\n",
            "\n",
            "Epoch 10|30:\n",
            "Batch 1|1608: loss 0.0069 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0367 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 201|1608: loss 0.0284 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 301|1608: loss 0.0263 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 401|1608: loss 0.0346 f1 76.92 precision 83.33 recall 71.43\n",
            "Batch 501|1608: loss 0.0329 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 601|1608: loss 0.0147 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0126 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0258 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 901|1608: loss 0.0132 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 1001|1608: loss 0.0267 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0097 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0156 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0141 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1401|1608: loss 0.0108 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0393 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1601|1608: loss 0.0457 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1608|1608: loss 0.0007 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0256 f1 68.09 precision 72.55 recall 67.48\n",
            "Time: 36.88\n",
            "Dev: loss 0.0641 f1 51.17 precision 63.57 recall 42.82\n",
            "\n",
            "Epoch 11|30:\n",
            "Batch 1|1608: loss 0.0301 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 101|1608: loss 0.0509 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 201|1608: loss 0.0125 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.0110 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0185 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 501|1608: loss 0.0088 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0316 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0029 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0303 f1 60.00 precision 75.00 recall 50.00\n",
            "Batch 901|1608: loss 0.0071 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0102 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0199 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1201|1608: loss 0.0309 f1 90.91 precision 100.00 recall 83.33\n",
            "Batch 1301|1608: loss 0.0235 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1401|1608: loss 0.0090 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1501|1608: loss 0.0147 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0839 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0822 f1 57.14 precision 66.67 recall 50.00\n",
            "Train: loss 0.0220 f1 72.03 precision 75.62 recall 72.06\n",
            "Time: 36.85\n",
            "Dev: loss 0.0618 f1 54.34 precision 57.40 recall 51.59\n",
            "Save model weight!\n",
            "\n",
            "Epoch 12|30:\n",
            "Batch 1|1608: loss 0.0148 f1 92.31 precision 100.00 recall 85.71\n",
            "Batch 101|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0049 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0211 f1 75.00 precision 100.00 recall 60.00\n",
            "Batch 501|1608: loss 0.0142 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 601|1608: loss 0.0199 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 701|1608: loss 0.0195 f1 83.33 precision 83.33 recall 83.33\n",
            "Batch 801|1608: loss 0.0081 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0189 f1 40.00 precision 33.33 recall 50.00\n",
            "Batch 1001|1608: loss 0.0212 f1 40.00 precision 33.33 recall 50.00\n",
            "Batch 1101|1608: loss 0.0325 f1 92.31 precision 85.71 recall 100.00\n",
            "Batch 1201|1608: loss 0.0318 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1301|1608: loss 0.0171 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0080 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0063 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0007 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0175 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0192 f1 75.40 precision 78.70 recall 75.16\n",
            "Time: 36.89\n",
            "Dev: loss 0.0647 f1 54.94 precision 58.19 recall 52.04\n",
            "Save model weight!\n",
            "\n",
            "Epoch 13|30:\n",
            "Batch 1|1608: loss 0.0033 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0098 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0169 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 301|1608: loss 0.0403 f1 83.33 precision 100.00 recall 71.43\n",
            "Batch 401|1608: loss 0.0130 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0165 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0731 f1 57.14 precision 100.00 recall 40.00\n",
            "Batch 701|1608: loss 0.0098 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 801|1608: loss 0.0148 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 901|1608: loss 0.0273 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1001|1608: loss 0.0047 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0226 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0305 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1301|1608: loss 0.0321 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1401|1608: loss 0.0211 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0078 f1 92.31 precision 85.71 recall 100.00\n",
            "Batch 1601|1608: loss 0.0032 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0219 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0172 f1 76.78 precision 79.44 recall 76.89\n",
            "Time: 36.84\n",
            "Dev: loss 0.0676 f1 54.26 precision 56.35 recall 52.32\n",
            "\n",
            "Epoch 14|30:\n",
            "Batch 1|1608: loss 0.0061 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0200 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 201|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0053 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0191 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0086 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0195 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 701|1608: loss 0.0092 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 801|1608: loss 0.0018 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0241 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1101|1608: loss 0.0478 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1201|1608: loss 0.0157 f1 94.12 precision 88.89 recall 100.00\n",
            "Batch 1301|1608: loss 0.0209 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1401|1608: loss 0.0051 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0131 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0199 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1608|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0152 f1 79.62 precision 81.66 recall 79.81\n",
            "Time: 36.82\n",
            "Dev: loss 0.0722 f1 51.46 precision 57.35 recall 46.67\n",
            "\n",
            "Epoch 15|30:\n",
            "Batch 1|1608: loss 0.0348 f1 57.14 precision 100.00 recall 40.00\n",
            "Batch 101|1608: loss 0.0225 f1 80.00 precision 75.00 recall 85.71\n",
            "Batch 201|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0116 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 401|1608: loss 0.0037 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0226 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0122 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 701|1608: loss 0.0702 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 801|1608: loss 0.0437 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 901|1608: loss 0.0266 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1001|1608: loss 0.0178 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0193 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0152 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0107 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0113 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1601|1608: loss 0.0111 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1608|1608: loss 0.0031 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0134 f1 82.76 precision 84.81 recall 82.98\n",
            "Time: 36.81\n",
            "Dev: loss 0.0730 f1 53.73 precision 55.93 recall 51.70\n",
            "\n",
            "Epoch 16|30:\n",
            "Batch 1|1608: loss 0.0054 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0041 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0357 f1 66.67 precision 75.00 recall 60.00\n",
            "Batch 301|1608: loss 0.0217 f1 72.73 precision 66.67 recall 80.00\n",
            "Batch 401|1608: loss 0.0297 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 501|1608: loss 0.0057 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0072 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0251 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 801|1608: loss 0.0148 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 901|1608: loss 0.0072 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0058 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0022 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0020 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0277 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1608|1608: loss 0.0088 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0126 f1 82.80 precision 84.49 recall 83.17\n",
            "Time: 37.03\n",
            "Dev: loss 0.0747 f1 52.75 precision 57.31 recall 48.85\n",
            "\n",
            "Epoch 17|30:\n",
            "Batch 1|1608: loss 0.0151 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0058 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0142 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0172 f1 93.33 precision 100.00 recall 87.50\n",
            "Batch 701|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0060 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0002 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0142 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0029 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0276 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1301|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0061 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0061 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0085 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0117 f1 82.88 precision 84.57 recall 83.18\n",
            "Time: 36.84\n",
            "Dev: loss 0.0773 f1 53.37 precision 53.35 recall 53.38\n",
            "\n",
            "Epoch 18|30:\n",
            "Batch 1|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0058 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0089 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 301|1608: loss 0.0118 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.0068 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0081 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0042 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0200 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1001|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0059 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0477 f1 72.73 precision 80.00 recall 66.67\n",
            "Batch 1301|1608: loss 0.0083 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0049 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0062 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0090 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0070 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0106 f1 85.17 precision 86.24 recall 85.78\n",
            "Time: 36.82\n",
            "Dev: loss 0.0790 f1 52.20 precision 57.90 recall 47.51\n",
            "\n",
            "Epoch 19|30:\n",
            "Batch 1|1608: loss 0.0056 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0097 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0359 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 301|1608: loss 0.0129 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0158 f1 87.50 precision 100.00 recall 77.78\n",
            "Batch 501|1608: loss 0.0181 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0102 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0057 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0155 f1 87.50 precision 87.50 recall 87.50\n",
            "Batch 901|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0153 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1101|1608: loss 0.0211 f1 80.00 precision 75.00 recall 85.71\n",
            "Batch 1201|1608: loss 0.0111 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 1301|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0205 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1501|1608: loss 0.0051 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0104 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0223 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0103 f1 86.20 precision 87.19 recall 86.71\n",
            "Time: 36.82\n",
            "Dev: loss 0.0804 f1 53.30 precision 55.51 recall 51.26\n",
            "\n",
            "Epoch 20|30:\n",
            "Batch 1|1608: loss 0.0022 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0029 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0027 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0103 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 701|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0010 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0178 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0067 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1101|1608: loss 0.0069 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0075 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0051 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0004 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0061 f1 87.50 precision 87.50 recall 87.50\n",
            "Batch 1601|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0042 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0100 f1 85.55 precision 86.80 recall 85.97\n",
            "Time: 36.85\n",
            "Dev: loss 0.0815 f1 52.57 precision 55.46 recall 49.97\n",
            "\n",
            "Epoch 21|30:\n",
            "Batch 1|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0362 f1 83.33 precision 71.43 recall 100.00\n",
            "Batch 401|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0294 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0000 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0060 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0044 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0055 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0184 f1 75.00 precision 100.00 recall 60.00\n",
            "Batch 1301|1608: loss 0.0189 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1401|1608: loss 0.0073 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0129 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0024 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0002 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0092 f1 85.72 precision 86.46 recall 86.45\n",
            "Time: 36.93\n",
            "Dev: loss 0.0843 f1 53.60 precision 58.18 recall 49.69\n",
            "\n",
            "Epoch 22|30:\n",
            "Batch 1|1608: loss 0.0117 f1 75.00 precision 100.00 recall 60.00\n",
            "Batch 101|1608: loss 0.0080 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 201|1608: loss 0.0602 f1 44.44 precision 40.00 recall 50.00\n",
            "Batch 301|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0029 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0320 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0003 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0110 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0124 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1201|1608: loss 0.0020 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0038 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0094 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1501|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0208 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0028 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0091 f1 87.03 precision 87.90 recall 87.71\n",
            "Time: 36.85\n",
            "Dev: loss 0.0854 f1 52.87 precision 58.24 recall 48.41\n",
            "\n",
            "Epoch 23|30:\n",
            "Batch 1|1608: loss 0.0144 f1 87.50 precision 87.50 recall 87.50\n",
            "Batch 101|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0071 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 401|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0006 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0024 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0031 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0265 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1201|1608: loss 0.0001 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0085 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0087 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1501|1608: loss 0.0061 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0395 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 1608|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0083 f1 87.85 precision 88.35 recall 88.88\n",
            "Time: 36.85\n",
            "Dev: loss 0.0876 f1 51.61 precision 60.10 recall 45.22\n",
            "\n",
            "Epoch 24|30:\n",
            "Batch 1|1608: loss 0.0091 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0048 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0063 f1 90.91 precision 100.00 recall 83.33\n",
            "Batch 501|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0036 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0560 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 801|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0038 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0284 f1 66.67 precision 60.00 recall 75.00\n",
            "Batch 1201|1608: loss 0.0118 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0190 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1601|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0086 f1 87.16 precision 88.11 recall 87.66\n",
            "Time: 36.86\n",
            "Dev: loss 0.0851 f1 53.39 precision 57.02 recall 50.20\n",
            "\n",
            "Epoch 25|30:\n",
            "Batch 1|1608: loss 0.0045 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0038 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0173 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 501|1608: loss 0.0051 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0312 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 701|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0071 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 901|1608: loss 0.0120 f1 94.12 precision 100.00 recall 88.89\n",
            "Batch 1001|1608: loss 0.0338 f1 94.12 precision 100.00 recall 88.89\n",
            "Batch 1101|1608: loss 0.0056 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0252 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0117 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1401|1608: loss 0.0100 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1501|1608: loss 0.0145 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1601|1608: loss 0.0201 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0078 f1 87.77 precision 88.34 recall 88.43\n",
            "Time: 36.84\n",
            "Dev: loss 0.0886 f1 53.48 precision 57.45 recall 50.03\n",
            "\n",
            "Epoch 26|30:\n",
            "Batch 1|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0244 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0074 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0288 f1 83.33 precision 100.00 recall 71.43\n",
            "Batch 801|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0055 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0209 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1501|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0188 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1608|1608: loss 0.0479 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0075 f1 87.99 precision 88.47 recall 88.69\n",
            "Time: 36.86\n",
            "Dev: loss 0.0907 f1 53.01 precision 59.94 recall 47.51\n",
            "\n",
            "Epoch 27|30:\n",
            "Batch 1|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0205 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.0040 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0053 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 501|1608: loss 0.0092 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 601|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0145 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0300 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1601|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0073 f1 88.38 precision 89.10 recall 89.07\n",
            "Time: 36.81\n",
            "Dev: loss 0.0860 f1 54.34 precision 55.15 recall 53.55\n",
            "\n",
            "Epoch 28|30:\n",
            "Batch 1|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0001 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0201 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 601|1608: loss 0.0257 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 701|1608: loss 0.0001 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0347 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1101|1608: loss 0.0020 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0213 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1401|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0176 f1 90.91 precision 83.33 recall 100.00\n",
            "Batch 1601|1608: loss 0.0364 f1 90.91 precision 83.33 recall 100.00\n",
            "Batch 1608|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0071 f1 88.71 precision 89.32 recall 89.38\n",
            "Time: 36.87\n",
            "Dev: loss 0.0869 f1 53.88 precision 56.78 recall 51.26\n",
            "\n",
            "Epoch 29|30:\n",
            "Batch 1|1608: loss 0.0284 f1 87.50 precision 87.50 recall 87.50\n",
            "Batch 101|1608: loss 0.0003 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 201|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0158 f1 95.24 precision 100.00 recall 90.91\n",
            "Batch 401|1608: loss 0.0002 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0056 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0157 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0189 f1 40.00 precision 33.33 recall 50.00\n",
            "Batch 1001|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0210 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1201|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0020 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0056 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0172 f1 66.67 precision 66.67 recall 66.67\n",
            "Train: loss 0.0074 f1 87.69 precision 88.26 recall 88.39\n",
            "Time: 36.90\n",
            "Dev: loss 0.0952 f1 51.33 precision 58.32 recall 45.84\n",
            "\n",
            "Epoch 30|30:\n",
            "Batch 1|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0181 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 401|1608: loss 0.0028 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0138 f1 94.12 precision 88.89 recall 100.00\n",
            "Batch 701|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0002 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0101 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1001|1608: loss 0.0136 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1101|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0001 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.0001 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0068 f1 89.97 precision 90.69 recall 90.54\n",
            "Time: 36.86\n",
            "Dev: loss 0.0911 f1 53.02 precision 58.78 recall 48.30\n",
            "\n",
            "Restore best model !\n",
            "Test: f1 54.90 precision 58.43 recall 51.77\n"
          ]
        }
      ],
      "source": [
        "! python bilstm_event_sentence.py --use_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhRJBBmdmQri",
        "outputId": "4e3914fc-2937-429e-acda-1a1d72756565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(no_train=False, train_batch_size=8, eval_batch_size=8, lr=0.0001, num_epochs=30, log_step=100, no_cuda=False, word_embedding_dim=300, use_pretrained=False, use_postag=False, postag_embedding_dim=25, hidden_size=512, dropout_rate=0.5)\n",
            "Epoch 1|30:\n",
            "Batch 1|1608: loss 3.5150 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 101|1608: loss 0.1455 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 201|1608: loss 0.0476 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.2401 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.2043 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.1498 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.1125 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.1356 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0696 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.1610 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0808 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0736 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.2480 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0954 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.0802 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0728 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.1874 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.3543 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.2085 f1 5.94 precision 11.41 recall 4.41\n",
            "Time: 34.86\n",
            "Dev: loss 0.1049 f1 22.56 precision 65.24 recall 13.64\n",
            "Save model weight!\n",
            "\n",
            "Epoch 2|30:\n",
            "Batch 1|1608: loss 0.1949 f1 40.00 precision 100.00 recall 25.00\n",
            "Batch 101|1608: loss 0.1865 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 201|1608: loss 0.0436 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 301|1608: loss 0.0556 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.0223 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0455 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0888 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0464 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 801|1608: loss 0.0480 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0204 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0666 f1 60.00 precision 75.00 recall 50.00\n",
            "Batch 1101|1608: loss 0.2098 f1 33.33 precision 100.00 recall 20.00\n",
            "Batch 1201|1608: loss 0.0473 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0742 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.2201 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.0576 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.0869 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.1113 f1 28.57 precision 50.00 recall 20.00\n",
            "Train: loss 0.0988 f1 30.04 precision 44.61 recall 25.12\n",
            "Time: 35.12\n",
            "Dev: loss 0.0810 f1 43.32 precision 62.71 recall 33.09\n",
            "Save model weight!\n",
            "\n",
            "Epoch 3|30:\n",
            "Batch 1|1608: loss 0.1536 f1 28.57 precision 100.00 recall 16.67\n",
            "Batch 101|1608: loss 0.0701 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 201|1608: loss 0.1434 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 301|1608: loss 0.0409 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.1115 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.1556 f1 25.00 precision 33.33 recall 20.00\n",
            "Batch 601|1608: loss 0.1056 f1 40.00 precision 100.00 recall 25.00\n",
            "Batch 701|1608: loss 0.0600 f1 44.44 precision 40.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0140 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 901|1608: loss 0.0249 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1001|1608: loss 0.0313 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0901 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.0991 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0738 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.0200 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1501|1608: loss 0.0291 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.0320 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0696 f1 80.00 precision 80.00 recall 80.00\n",
            "Train: loss 0.0784 f1 38.83 precision 51.79 recall 34.44\n",
            "Time: 36.83\n",
            "Dev: loss 0.0738 f1 45.98 precision 59.98 recall 37.28\n",
            "Save model weight!\n",
            "\n",
            "Epoch 4|30:\n",
            "Batch 1|1608: loss 0.2064 f1 44.44 precision 66.67 recall 33.33\n",
            "Batch 101|1608: loss 0.0748 f1 50.00 precision 66.67 recall 40.00\n",
            "Batch 201|1608: loss 0.1220 f1 50.00 precision 66.67 recall 40.00\n",
            "Batch 301|1608: loss 0.0455 f1 90.91 precision 83.33 recall 100.00\n",
            "Batch 401|1608: loss 0.0352 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 501|1608: loss 0.1055 f1 18.18 precision 25.00 recall 14.29\n",
            "Batch 601|1608: loss 0.0711 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 701|1608: loss 0.0344 f1 90.91 precision 100.00 recall 83.33\n",
            "Batch 801|1608: loss 0.1217 f1 20.00 precision 25.00 recall 16.67\n",
            "Batch 901|1608: loss 0.0276 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0251 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 1101|1608: loss 0.0188 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1201|1608: loss 0.0354 f1 33.33 precision 25.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.0388 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1401|1608: loss 0.0449 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1501|1608: loss 0.1482 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.1168 f1 54.55 precision 75.00 recall 42.86\n",
            "Batch 1608|1608: loss 0.0105 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0646 f1 44.33 precision 55.27 recall 40.84\n",
            "Time: 37.14\n",
            "Dev: loss 0.0766 f1 41.24 precision 65.89 recall 30.02\n",
            "\n",
            "Epoch 5|30:\n",
            "Batch 1|1608: loss 0.1184 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 101|1608: loss 0.0370 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 201|1608: loss 0.0259 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 301|1608: loss 0.0931 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.0753 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 501|1608: loss 0.0366 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 601|1608: loss 0.0110 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0320 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0774 f1 20.00 precision 20.00 recall 20.00\n",
            "Batch 901|1608: loss 0.0691 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0256 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1101|1608: loss 0.0946 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1201|1608: loss 0.0119 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0269 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 1401|1608: loss 0.0929 f1 55.56 precision 71.43 recall 45.45\n",
            "Batch 1501|1608: loss 0.0315 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1601|1608: loss 0.0080 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0131 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0539 f1 50.26 precision 60.01 recall 47.17\n",
            "Time: 36.77\n",
            "Dev: loss 0.0693 f1 47.16 precision 60.81 recall 38.51\n",
            "Save model weight!\n",
            "\n",
            "Epoch 6|30:\n",
            "Batch 1|1608: loss 0.0539 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 101|1608: loss 0.0875 f1 50.00 precision 66.67 recall 40.00\n",
            "Batch 201|1608: loss 0.0221 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 301|1608: loss 0.0426 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 401|1608: loss 0.0746 f1 28.57 precision 33.33 recall 25.00\n",
            "Batch 501|1608: loss 0.0143 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 601|1608: loss 0.0343 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 701|1608: loss 0.0266 f1 66.67 precision 60.00 recall 75.00\n",
            "Batch 801|1608: loss 0.0090 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0192 f1 40.00 precision 33.33 recall 50.00\n",
            "Batch 1001|1608: loss 0.1147 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0812 f1 40.00 precision 100.00 recall 25.00\n",
            "Batch 1201|1608: loss 0.0393 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 1301|1608: loss 0.0083 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0297 f1 92.31 precision 100.00 recall 85.71\n",
            "Batch 1501|1608: loss 0.0371 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.0114 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0210 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0443 f1 56.18 precision 64.47 recall 53.59\n",
            "Time: 37.02\n",
            "Dev: loss 0.0698 f1 51.52 precision 55.72 recall 47.90\n",
            "Save model weight!\n",
            "\n",
            "Epoch 7|30:\n",
            "Batch 1|1608: loss 0.0223 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0103 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0561 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.0444 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 401|1608: loss 0.0238 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0201 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 601|1608: loss 0.0244 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0722 f1 40.00 precision 50.00 recall 33.33\n",
            "Batch 801|1608: loss 0.0181 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 901|1608: loss 0.0946 f1 57.14 precision 57.14 recall 57.14\n",
            "Batch 1001|1608: loss 0.0275 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0089 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0331 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0777 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1401|1608: loss 0.0057 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0463 f1 72.73 precision 66.67 recall 80.00\n",
            "Batch 1601|1608: loss 0.0162 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0126 f1 66.67 precision 100.00 recall 50.00\n",
            "Train: loss 0.0368 f1 62.33 precision 70.27 recall 59.92\n",
            "Time: 36.82\n",
            "Dev: loss 0.0738 f1 48.55 precision 58.31 recall 41.59\n",
            "\n",
            "Epoch 8|30:\n",
            "Batch 1|1608: loss 0.0266 f1 92.31 precision 100.00 recall 85.71\n",
            "Batch 101|1608: loss 0.0140 f1 90.91 precision 100.00 recall 83.33\n",
            "Batch 201|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0066 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0096 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 601|1608: loss 0.0241 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 701|1608: loss 0.0115 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 801|1608: loss 0.0138 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 901|1608: loss 0.0375 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0260 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1101|1608: loss 0.1642 f1 60.00 precision 75.00 recall 50.00\n",
            "Batch 1201|1608: loss 0.0108 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0138 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0324 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1501|1608: loss 0.0648 f1 61.54 precision 66.67 recall 57.14\n",
            "Batch 1601|1608: loss 0.0120 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0299 f1 66.58 precision 72.64 recall 64.73\n",
            "Time: 36.82\n",
            "Dev: loss 0.0765 f1 49.38 precision 57.60 recall 43.21\n",
            "\n",
            "Epoch 9|30:\n",
            "Batch 1|1608: loss 0.0452 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 101|1608: loss 0.0471 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 201|1608: loss 0.0092 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0115 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 401|1608: loss 0.0151 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0403 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0095 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0079 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0082 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 901|1608: loss 0.0408 f1 60.00 precision 75.00 recall 50.00\n",
            "Batch 1001|1608: loss 0.0107 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0031 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0280 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1301|1608: loss 0.0336 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1401|1608: loss 0.0115 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0062 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0131 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0662 f1 80.00 precision 100.00 recall 66.67\n",
            "Train: loss 0.0243 f1 71.44 precision 76.14 recall 70.30\n",
            "Time: 36.84\n",
            "Dev: loss 0.0753 f1 51.37 precision 57.88 recall 46.17\n",
            "\n",
            "Epoch 10|30:\n",
            "Batch 1|1608: loss 0.0369 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 101|1608: loss 0.0104 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0316 f1 93.33 precision 100.00 recall 87.50\n",
            "Batch 301|1608: loss 0.0452 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 401|1608: loss 0.0040 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0428 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 601|1608: loss 0.0155 f1 66.67 precision 75.00 recall 60.00\n",
            "Batch 701|1608: loss 0.0215 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0054 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0485 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0135 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1101|1608: loss 0.0292 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0140 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.0064 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0136 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0473 f1 33.33 precision 33.33 recall 33.33\n",
            "Batch 1601|1608: loss 0.0108 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0009 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0205 f1 75.09 precision 79.06 recall 74.42\n",
            "Time: 36.83\n",
            "Dev: loss 0.0826 f1 48.46 precision 56.70 recall 42.31\n",
            "\n",
            "Epoch 11|30:\n",
            "Batch 1|1608: loss 0.0105 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 101|1608: loss 0.0157 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 201|1608: loss 0.0100 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0232 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 401|1608: loss 0.0376 f1 90.91 precision 100.00 recall 83.33\n",
            "Batch 501|1608: loss 0.0080 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0114 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 701|1608: loss 0.0045 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0305 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 901|1608: loss 0.0081 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0117 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0202 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1201|1608: loss 0.0152 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1301|1608: loss 0.0166 f1 57.14 precision 50.00 recall 66.67\n",
            "Batch 1401|1608: loss 0.0177 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1501|1608: loss 0.0111 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1601|1608: loss 0.0379 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1608|1608: loss 0.0007 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0174 f1 77.74 precision 80.90 recall 77.17\n",
            "Time: 36.80\n",
            "Dev: loss 0.0859 f1 49.58 precision 58.88 recall 42.82\n",
            "\n",
            "Epoch 12|30:\n",
            "Batch 1|1608: loss 0.0057 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0099 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0031 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0675 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0419 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 601|1608: loss 0.0332 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 701|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0111 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0111 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0448 f1 71.43 precision 71.43 recall 71.43\n",
            "Batch 1501|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0034 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0022 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0151 f1 80.52 precision 83.20 recall 80.27\n",
            "Time: 36.90\n",
            "Dev: loss 0.0948 f1 46.07 precision 60.56 recall 37.17\n",
            "\n",
            "Epoch 13|30:\n",
            "Batch 1|1608: loss 0.0034 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0266 f1 94.74 precision 100.00 recall 90.00\n",
            "Batch 301|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0176 f1 72.73 precision 80.00 recall 66.67\n",
            "Batch 501|1608: loss 0.0046 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0109 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 701|1608: loss 0.0665 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 801|1608: loss 0.0064 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0046 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0025 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0054 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0049 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0229 f1 93.33 precision 100.00 recall 87.50\n",
            "Batch 1501|1608: loss 0.0127 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0028 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0138 f1 83.07 precision 85.00 recall 83.14\n",
            "Time: 36.82\n",
            "Dev: loss 0.0931 f1 48.85 precision 60.83 recall 40.80\n",
            "\n",
            "Epoch 14|30:\n",
            "Batch 1|1608: loss 0.0142 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 101|1608: loss 0.0233 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 201|1608: loss 0.0193 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 301|1608: loss 0.0186 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0656 f1 75.00 precision 60.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0196 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 601|1608: loss 0.0110 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 701|1608: loss 0.0285 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 801|1608: loss 0.0046 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0090 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0042 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0027 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0036 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0094 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1501|1608: loss 0.0317 f1 82.35 precision 87.50 recall 77.78\n",
            "Batch 1601|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0003 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0120 f1 84.72 precision 86.34 recall 84.99\n",
            "Time: 36.76\n",
            "Dev: loss 0.0933 f1 48.97 precision 58.00 recall 42.37\n",
            "\n",
            "Epoch 15|30:\n",
            "Batch 1|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0002 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 201|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0121 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 401|1608: loss 0.0011 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0411 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0349 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0598 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1001|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0340 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1201|1608: loss 0.0088 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 1301|1608: loss 0.0004 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0058 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0062 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0008 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0114 f1 85.82 precision 87.37 recall 86.00\n",
            "Time: 36.90\n",
            "Dev: loss 0.0949 f1 49.77 precision 60.53 recall 42.26\n",
            "\n",
            "Epoch 16|30:\n",
            "Batch 1|1608: loss 0.0051 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0279 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0073 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 301|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0291 f1 83.33 precision 83.33 recall 83.33\n",
            "Batch 601|1608: loss 0.0163 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 701|1608: loss 0.0129 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 801|1608: loss 0.0060 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0299 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1001|1608: loss 0.0004 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1101|1608: loss 0.0089 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0053 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0123 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0186 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1601|1608: loss 0.0229 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1608|1608: loss 0.0035 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0099 f1 86.05 precision 87.32 recall 86.40\n",
            "Time: 36.82\n",
            "Dev: loss 0.0988 f1 47.74 precision 59.52 recall 39.85\n",
            "\n",
            "Epoch 17|30:\n",
            "Batch 1|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0056 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0053 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0288 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 601|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0080 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0225 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1001|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0031 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0095 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0020 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0133 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 1601|1608: loss 0.0033 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0059 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0097 f1 86.55 precision 87.82 recall 86.94\n",
            "Time: 36.82\n",
            "Dev: loss 0.1046 f1 47.02 precision 58.76 recall 39.18\n",
            "\n",
            "Epoch 18|30:\n",
            "Batch 1|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0035 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0065 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0126 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 401|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0326 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 901|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0223 f1 92.31 precision 100.00 recall 85.71\n",
            "Batch 1301|1608: loss 0.0024 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0266 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1501|1608: loss 0.0080 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1601|1608: loss 0.0033 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0036 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0089 f1 86.62 precision 87.59 recall 87.09\n",
            "Time: 36.87\n",
            "Dev: loss 0.0974 f1 49.43 precision 57.06 recall 43.60\n",
            "\n",
            "Epoch 19|30:\n",
            "Batch 1|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0026 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0155 f1 92.31 precision 85.71 recall 100.00\n",
            "Batch 501|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0078 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0187 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 901|1608: loss 0.0620 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1001|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0391 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1201|1608: loss 0.0117 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0066 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0053 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0036 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0142 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1608|1608: loss 0.0088 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0087 f1 87.56 precision 88.45 recall 88.11\n",
            "Time: 36.83\n",
            "Dev: loss 0.0992 f1 50.40 precision 56.49 recall 45.50\n",
            "\n",
            "Epoch 20|30:\n",
            "Batch 1|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0139 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0160 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0558 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0094 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0088 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 801|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0141 f1 90.91 precision 83.33 recall 100.00\n",
            "Batch 1101|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0419 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1301|1608: loss 0.0089 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0154 f1 80.00 precision 100.00 recall 66.67\n",
            "Batch 1501|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0077 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0083 f1 87.44 precision 88.38 recall 88.01\n",
            "Time: 36.90\n",
            "Dev: loss 0.1015 f1 50.02 precision 58.75 recall 43.54\n",
            "\n",
            "Epoch 21|30:\n",
            "Batch 1|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0050 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0061 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0001 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 501|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0106 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 901|1608: loss 0.0555 f1 50.00 precision 100.00 recall 33.33\n",
            "Batch 1001|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0304 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 1201|1608: loss 0.0093 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0477 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0033 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0034 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0070 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0241 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0075 f1 88.47 precision 89.09 recall 89.14\n",
            "Time: 37.08\n",
            "Dev: loss 0.1106 f1 47.93 precision 57.97 recall 40.86\n",
            "\n",
            "Epoch 22|30:\n",
            "Batch 1|1608: loss 0.0051 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0071 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0217 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0118 f1 50.00 precision 33.33 recall 100.00\n",
            "Batch 501|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0035 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0030 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0043 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0107 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1001|1608: loss 0.0066 f1 92.31 precision 100.00 recall 85.71\n",
            "Batch 1101|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0058 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.0049 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0223 f1 66.67 precision 66.67 recall 66.67\n",
            "Train: loss 0.0073 f1 88.90 precision 89.77 recall 89.49\n",
            "Time: 36.85\n",
            "Dev: loss 0.1084 f1 48.97 precision 60.13 recall 41.31\n",
            "\n",
            "Epoch 23|30:\n",
            "Batch 1|1608: loss 0.0311 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 101|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0089 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 401|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0400 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 601|1608: loss 0.0085 f1 85.71 precision 85.71 recall 85.71\n",
            "Batch 701|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0019 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0106 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0078 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0072 f1 88.95 precision 89.72 recall 89.54\n",
            "Time: 36.94\n",
            "Dev: loss 0.1097 f1 47.83 precision 57.55 recall 40.92\n",
            "\n",
            "Epoch 24|30:\n",
            "Batch 1|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0218 f1 80.00 precision 80.00 recall 80.00\n",
            "Batch 301|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0063 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0074 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0024 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0052 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0018 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0466 f1 83.33 precision 100.00 recall 71.43\n",
            "Batch 1401|1608: loss 0.0114 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1501|1608: loss 0.0133 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0373 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1608|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0067 f1 88.83 precision 89.37 recall 89.45\n",
            "Time: 36.89\n",
            "Dev: loss 0.1096 f1 50.69 precision 59.38 recall 44.21\n",
            "\n",
            "Epoch 25|30:\n",
            "Batch 1|1608: loss 0.0005 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0031 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0918 f1 44.44 precision 40.00 recall 50.00\n",
            "Batch 401|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0028 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0275 f1 90.91 precision 100.00 recall 83.33\n",
            "Batch 701|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0166 f1 94.12 precision 100.00 recall 88.89\n",
            "Batch 1001|1608: loss 0.0054 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0009 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0016 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0140 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 1401|1608: loss 0.0020 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0002 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0067 f1 88.54 precision 89.21 recall 89.12\n",
            "Time: 36.89\n",
            "Dev: loss 0.1166 f1 47.25 precision 59.51 recall 39.18\n",
            "\n",
            "Epoch 26|30:\n",
            "Batch 1|1608: loss 0.0023 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0057 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0036 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0186 f1 50.00 precision 50.00 recall 50.00\n",
            "Batch 901|1608: loss 0.0045 f1 80.00 precision 66.67 recall 100.00\n",
            "Batch 1001|1608: loss 0.0062 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0216 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 1301|1608: loss 0.0116 f1 88.89 precision 100.00 recall 80.00\n",
            "Batch 1401|1608: loss 0.0378 f1 57.14 precision 66.67 recall 50.00\n",
            "Batch 1501|1608: loss 0.0290 f1 50.00 precision 66.67 recall 40.00\n",
            "Batch 1601|1608: loss 0.0014 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0065 f1 89.41 precision 89.98 recall 90.15\n",
            "Time: 36.82\n",
            "Dev: loss 0.1148 f1 49.25 precision 59.23 recall 42.15\n",
            "\n",
            "Epoch 27|30:\n",
            "Batch 1|1608: loss 0.0001 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0163 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0391 f1 72.73 precision 66.67 recall 80.00\n",
            "Batch 301|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0092 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0064 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0001 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0205 f1 72.73 precision 80.00 recall 66.67\n",
            "Batch 1301|1608: loss 0.0124 f1 66.67 precision 100.00 recall 50.00\n",
            "Batch 1401|1608: loss 0.0033 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0216 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0039 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0063 f1 89.04 precision 89.51 recall 89.83\n",
            "Time: 37.00\n",
            "Dev: loss 0.1129 f1 48.51 precision 58.74 recall 41.31\n",
            "\n",
            "Epoch 28|30:\n",
            "Batch 1|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 101|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0032 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0036 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0017 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0117 f1 66.67 precision 50.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0007 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0001 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0015 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0028 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0063 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0037 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0060 f1 88.98 precision 89.58 recall 89.54\n",
            "Time: 37.00\n",
            "Dev: loss 0.1103 f1 49.46 precision 57.62 recall 43.32\n",
            "\n",
            "Epoch 29|30:\n",
            "Batch 1|1608: loss 0.0053 f1 83.33 precision 83.33 recall 83.33\n",
            "Batch 101|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0003 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 301|1608: loss 0.0158 f1 85.71 precision 100.00 recall 75.00\n",
            "Batch 401|1608: loss 0.0033 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 601|1608: loss 0.0028 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 801|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 901|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0012 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0037 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 1401|1608: loss 0.0031 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0042 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0010 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Train: loss 0.0059 f1 89.31 precision 89.88 recall 90.08\n",
            "Time: 36.89\n",
            "Dev: loss 0.1165 f1 49.92 precision 58.28 recall 43.66\n",
            "\n",
            "Epoch 30|30:\n",
            "Batch 1|1608: loss 0.0240 f1 92.31 precision 100.00 recall 85.71\n",
            "Batch 101|1608: loss 0.0013 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 201|1608: loss 0.0008 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 301|1608: loss 0.0011 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 401|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 501|1608: loss 0.0113 f1 75.00 precision 75.00 recall 75.00\n",
            "Batch 601|1608: loss 0.0003 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 701|1608: loss 0.0001 f1 0.00 precision 0.00 recall 0.00\n",
            "Batch 801|1608: loss 0.0183 f1 66.67 precision 66.67 recall 66.67\n",
            "Batch 901|1608: loss 0.0146 f1 85.71 precision 75.00 recall 100.00\n",
            "Batch 1001|1608: loss 0.0021 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1101|1608: loss 0.0006 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1201|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1301|1608: loss 0.0081 f1 88.89 precision 80.00 recall 100.00\n",
            "Batch 1401|1608: loss 0.0002 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1501|1608: loss 0.0001 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1601|1608: loss 0.0004 f1 100.00 precision 100.00 recall 100.00\n",
            "Batch 1608|1608: loss 0.0000 f1 0.00 precision 0.00 recall 0.00\n",
            "Train: loss 0.0056 f1 89.58 precision 90.07 recall 90.29\n",
            "Time: 36.81\n",
            "Dev: loss 0.1189 f1 49.89 precision 60.19 recall 42.59\n",
            "\n",
            "Restore best model !\n",
            "Test: f1 51.45 precision 56.37 recall 47.33\n"
          ]
        }
      ],
      "source": [
        "! python bilstm_event_sentence.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
